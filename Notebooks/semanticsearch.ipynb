{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow_hub\n","  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting transformers\n","  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /home/codespace/.local/lib/python3.10/site-packages (2.12.0)\n","Requirement already satisfied: python-dotenv in /home/codespace/.local/lib/python3.10/site-packages (0.19.1)\n","Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (2.0.2)\n","Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (1.23.5)\n","Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (1.5.0)\n","Requirement already satisfied: protobuf>=3.19.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_hub) (4.25.3)\n","Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n","  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (3.14.0)\n","Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n","  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Collecting regex!=2019.12.17 (from transformers)\n","  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (2.26.0)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting tqdm>=4.27 (from transformers)\n","  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: h5py>=2.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: jax>=0.3.15 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (0.4.29)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (70.0.0)\n","Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.12.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n","Requirement already satisfied: ml-dtypes>=0.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.30.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Collecting tensorflow\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n","  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow\n","  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n","  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (2.0.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/codespace/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n","Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tqdm, tf-keras, safetensors, regex, tensorflow_hub, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.23.3 regex-2024.5.15 safetensors-0.4.3 tensorflow_hub-0.16.1 tf-keras-2.15.0 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tensorflow_hub transformers tensorflow python-dotenv pandas numpy scikit-learn"]},{"cell_type":"markdown","metadata":{},"source":["## Import Necessary Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2DwTz3CTuxfc"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-13 07:46:57.136319: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-06-13 07:46:57.192923: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-06-13 07:46:57.194223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-13 07:46:58.531642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import requests\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from dotenv import load_dotenv\n","from transformers import BertTokenizer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27948,"status":"ok","timestamp":1717396779935,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"OW6SJaIT0rzn","outputId":"e817fa52-6cd0-4198-f854-346985d0b875"},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to fetch data from http://161.97.109.65:3000/api/products: 403 Client Error: Forbidden for url: http://161.97.109.65:3000/api/products\n","Data fetching failed, check errors and retry.\n"]}],"source":["load_dotenv()  # Load environment variables from .env file\n","jwt_token = os.getenv('JWT_TOKEN')\n","\n","headers = {'Authorization': f'Bearer {jwt_token}'}\n","\n","api_urls = {\n","    'products': 'http://161.97.109.65:3000/api/products'\n","}\n","\n","def fetch_data(url, headers):\n","    try:\n","        response = requests.get(url, headers=headers)\n","        response.raise_for_status()  # Raises an HTTPError for bad requests\n","        data = pd.DataFrame(response.json())\n","        print(f\"Data successfully fetched from {url}\")\n","        print(data.head())  # Display the first few rows of the DataFrame\n","        return data\n","    except requests.RequestException as e:\n","        print(f'Failed to fetch data from {url}: {str(e)}')\n","        return pd.DataFrame()\n","\n","# Fetch data from APIs\n","products = fetch_data(api_urls['products'], headers)\n","\n","# Check if   data was fetched successfully\n","if not products.empty:\n","    print(\"All data fetched successfully.\")\n","else:\n","    print(\"Data fetching failed, check errors and retry.\")\n","    # Optionally, add logic to halt further processing if data is crucial"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Ic9Dzmdxx0vD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: []\n","Index: []\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.python/current/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"ename":"KeyError","evalue":"'name'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(\n\u001b[1;32m      9\u001b[0m         texts\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     10\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming the data contains a column named 'name'\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m tokenize_data(\u001b[43mproducts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, tokenizer)\n\u001b[1;32m     18\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenized_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m tokenized_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n","\u001b[0;31mKeyError\u001b[0m: 'name'"]}],"source":["print(products.head())\n","\n","# Initialize the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize the text data\n","def tokenize_data(texts, tokenizer, max_length=128):\n","    return tokenizer(\n","        texts.tolist(),\n","        max_length=max_length,\n","        truncation=True,\n","        padding='max_length',\n","        return_tensors='tf'\n","    )\n","\n","# Assuming the data contains a column named 'name'\n","tokenized_data = tokenize_data(products['name'], tokenizer)\n","input_ids = tokenized_data['input_ids']\n","attention_masks = tokenized_data['attention_mask']\n","\n","# Convert tensors to numpy arrays\n","input_ids_np = input_ids.numpy()\n","attention_masks_np = attention_masks.numpy()\n","\n","# Create dummy binary labels for demonstration purposes\n","# Example: Assign a label based on a condition, here assuming 'Meja' category as 1 and others as 0\n","labels = (products['category'] == 'Category1').astype(int).values  # Example binary labels based on category\n","\n","# Split the data\n","train_input_ids, val_input_ids, train_labels, val_labels = train_test_split(input_ids_np, labels, test_size=0.2, random_state=42)\n","train_attention_masks, val_attention_masks = train_test_split(attention_masks_np, test_size=0.2, random_state=42)\n","\n","# Check the shapes of the splits to ensure correctness\n","print(f\"Train input IDs shape: {train_input_ids.shape}\")\n","print(f\"Validation input IDs shape: {val_input_ids.shape}\")\n","print(f\"Train attention masks shape: {train_attention_masks.shape}\")\n","print(f\"Validation attention masks shape: {val_attention_masks.shape}\")\n","print(f\"Train labels shape: {train_labels.shape}\")\n","print(f\"Validation labels shape: {val_labels.shape}\")\n","\n","# Combine product name and category for Universal Sentence Encoder\n","titles = products['name'].tolist()\n","labels = products['category'].tolist()\n","combined_text = [f\"{label} {title}\" for label, title in zip(labels, titles)]\n","\n","# Load the Universal Sentence Encoder\n","embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","\n","# Generate embeddings for the combined text\n","embeddings = embed(combined_text)\n","\n","# Check the shape of the embeddings\n","print(embeddings.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Create Model"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7zXo0P8kyT3w"},"outputs":[],"source":["# Define the search function\n","def semantic_search(query, embeddings, data, top_k):\n","    # Generate the embedding for the query\n","    query_embedding = embed([query])\n","\n","    # Calculate cosine similarities\n","    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n","\n","    # Get the top_k products\n","    top_k_indices = np.argsort(similarities)[-top_k:][::-1]  # Corrected this line to use argsort\n","    if len(top_k_indices) == 0:\n","        return None  # Return None if no results found\n","    results = data.iloc[top_k_indices]\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["# Try Model"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1717399763540,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"xlx27-JwyYP3","outputId":"66511078-add1-4990-e25e-40246b893fb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["                          _id category     price  \\\n","345  6667ef73b3e75416b2fa7f8c    Kasur  185000.0   \n","423  6667ef73b3e75416b2fa7fda    Kasur  226320.0   \n","391  6667ef73b3e75416b2fa7fba    Kasur   61281.0   \n","324  6667ef73b3e75416b2fa7f77    Kasur   55900.0   \n","384  6667ef73b3e75416b2fa7fb3    Kasur   64000.0   \n","340  6667ef73b3e75416b2fa7f87    Kasur   90000.0   \n","295  6667ef73b3e75416b2fa7f5a    Kasur  498000.0   \n","356  6667ef73b3e75416b2fa7f97    Kasur  224000.0   \n","317  6667ef73b3e75416b2fa7f70    Kasur   98000.0   \n","381  6667ef73b3e75416b2fa7fb0    Kasur  149000.0   \n","\n","                                                  name  \\\n","345                                       kasur dewasa   \n","423  Kasur Lantai MOLLORCA 100cm/kasurlipat/kasurva...   \n","391       Kasur lipat matras kasur lantai (90x170x5cm)   \n","324               KASUR LIPAT 90x170x5cm...SUPER MURAH   \n","384              Kasur Lantai Palembang Empuk Termurah   \n","340  kasur palembang, kasur kapuk, kasur lantai, ka...   \n","295      Kasur Springbed Bigland Bigpoint [JAWA TIMUR]   \n","356  JUAL RUGI Kasur Springbed Olympic Bearland - J...   \n","317     kasur busa lipat /kasur lipat/kasur travelling   \n","381  Kasur bulu rasfur lantai / Kasur gender bulu f...   \n","\n","                     sellerId  \\\n","345  6665e9847aa0dfec0ad43b26   \n","423  6665e9847aa0dfec0ad43b26   \n","391  6665e9847aa0dfec0ad43b26   \n","324  6665e9847aa0dfec0ad43b26   \n","384  6665e9847aa0dfec0ad43b26   \n","340  6665e9847aa0dfec0ad43b26   \n","295  6665e9847aa0dfec0ad43b26   \n","356  6665e9847aa0dfec0ad43b26   \n","317  6665e9847aa0dfec0ad43b26   \n","381  6665e9847aa0dfec0ad43b26   \n","\n","                                          productImage  __v  \n","345  [https://storage.googleapis.com/kelas-app-test...    0  \n","423  [https://storage.googleapis.com/kelas-app-test...    0  \n","391  [https://storage.googleapis.com/kelas-app-test...    0  \n","324  [https://storage.googleapis.com/kelas-app-test...    0  \n","384  [https://storage.googleapis.com/kelas-app-test...    0  \n","340  [https://storage.googleapis.com/kelas-app-test...    0  \n","295  [https://storage.googleapis.com/kelas-app-test...    0  \n","356  [https://storage.googleapis.com/kelas-app-test...    0  \n","317  [https://storage.googleapis.com/kelas-app-test...    0  \n","381  [https://storage.googleapis.com/kelas-app-test...    0  \n"]}],"source":["# Example usage\n","query = \"kasur\"\n","results = semantic_search(query, embeddings, products, top_k=10)\n","\n","print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
