{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\users\\user\\miniconda3\\lib\\site-packages (2.16.1)\n","Requirement already satisfied: tensorflow-hub in c:\\users\\user\\miniconda3\\lib\\site-packages (0.16.1)\n","Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\lib\\site-packages (2.2.2)\n","Requirement already satisfied: numpy in c:\\users\\user\\miniconda3\\lib\\site-packages (1.26.4)\n","Requirement already satisfied: scikit-learn in c:\\users\\user\\miniconda3\\lib\\site-packages (1.5.0)\n","Requirement already satisfied: python-dotenv in c:\\users\\user\\miniconda3\\lib\\site-packages (1.0.1)\n","Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n","Requirement already satisfied: keras>=3.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorflow-hub) (2.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n","Requirement already satisfied: rich in c:\\users\\user\\miniconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in c:\\users\\user\\miniconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in c:\\users\\user\\miniconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install --upgrade tensorflow tensorflow-hub pandas numpy scikit-learn python-dotenv"]},{"cell_type":"markdown","metadata":{},"source":["## Import Necessary Libraries"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2DwTz3CTuxfc"},"outputs":[],"source":["import os\n","import requests\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from dotenv import load_dotenv"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27948,"status":"ok","timestamp":1717396779935,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"OW6SJaIT0rzn","outputId":"e817fa52-6cd0-4198-f854-346985d0b875"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data successfully fetched from http://161.97.109.65:3000/api/products\n","                        _id    name         category description  price  \\\n","0  6665935c2b9108ea2b463dc2  bababa  asdadaasdadaasd  1234567890     25   \n","\n","                   sellerId  \\\n","0  666545a42b9108ea2b463d87   \n","\n","                                        productImage  __v  \n","0  [https://storage.googleapis.com/kelas-app-test...    0  \n","All data fetched successfully.\n"]}],"source":["load_dotenv()  # Load environment variables from .env file\n","jwt_token = os.getenv('JWT_TOKEN')\n","\n","headers = {'Authorization': f'Bearer {jwt_token}'}\n","\n","api_urls = {\n","    'products': 'http://161.97.109.65:3000/api/products'\n","}\n","\n","def fetch_data(url, headers):\n","    try:\n","        response = requests.get(url, headers=headers)\n","        response.raise_for_status()  # Raises an HTTPError for bad requests\n","        data = pd.DataFrame(response.json())\n","        print(f\"Data successfully fetched from {url}\")\n","        print(data.head())  # Display the first few rows of the DataFrame\n","        return data\n","    except requests.RequestException as e:\n","        print(f'Failed to fetch data from {url}: {str(e)}')\n","        return pd.DataFrame()\n","\n","# Fetch data from APIs\n","products = fetch_data(api_urls['products'], headers)\n","\n","# Check if data was fetched successfully\n","if not products.empty:\n","    print(\"All data fetched successfully.\")\n","else:\n","    print(\"Data fetching failed, check errors and retry.\")\n","    # Optionally, add logic to halt further processing if data is crucial"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ic9Dzmdxx0vD"},"outputs":[],"source":["titles = products['name'].tolist()\n","labels = products['category'].tolist()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"n4XGlJsVyP8z"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (1653464730.py, line 11)","output_type":"error","traceback":["\u001b[1;36m  Cell \u001b[1;32mIn[14], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    tf.io.gfile.makedirs instead of tf.gfile.MakeDirs\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["# Combine title and label for better semantic understanding\n","combined_text = [f\"{label} {title}\" for label, title in zip(labels, titles)]\n","\n","# Load the Universal Sentence Encoder\n","embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","\n","# Generate embeddings for the combined descriptions\n","embeddings = embed(combined_text)\n","\n","# Handling deprecated warnings by updating to current functions\n","tf.io.gfile.makedirs instead of tf.gfile.MakeDirs\n","tf.compat.v2.saved_model.load instead of tf.saved_model.load_v2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zXo0P8kyT3w"},"outputs":[],"source":["# Define the search function\n","def semantic_search(query, embeddings, data, top_k):\n","    # Generate the embedding for the query\n","    query_embedding = embed([query])\n","\n","    # Calculate cosine similarities\n","    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n","    # Get the top_k products\n","    top_k_indices = np.where(similarities > 0.3)[0][-top_k:][::-1]\n","    if len(top_k_indices) == 0:\n","        return None  # Return None if no results found\n","    results = data.iloc[top_k_indices]\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1717399763540,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"xlx27-JwyYP3","outputId":"66511078-add1-4990-e25e-40246b893fb2"},"outputs":[{"ename":"NameError","evalue":"name 'datas' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkasur lipat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m semantic_search(query, embeddings, datas, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n","\u001b[1;31mNameError\u001b[0m: name 'datas' is not defined"]}],"source":["# Example usage\n","query = \"kasur lipat\"\n","results = semantic_search(query, embeddings, datas, top_k=20)\n","\n","print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RNK9izj8PDI"},"outputs":[],"source":["query_embedding = embed([query])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRyeZFZ08Iht"},"outputs":[],"source":["similarities = cosine_similarity(query_embedding, embeddings).flatten()\n","similarities = similarities[similarities>0.3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":725,"status":"ok","timestamp":1717079999947,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"sXiyNRt_8Wwy","outputId":"cf577ecc-afc9-4cf4-ec5d-e84272914df4"},"outputs":[],"source":["similarities"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1136,"status":"ok","timestamp":1717080047936,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"rdJsMJ8n8fLg","outputId":"3c00003f-2d44-40c0-850c-1b866988ebc4"},"outputs":[],"source":["top_k_indices = similarities.argsort()[-5:][::-1]\n","top_k_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":107584,"status":"ok","timestamp":1717080450633,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"qc1Qzlbg9oQC","outputId":"7b3718d9-e680-429d-91db-d5b7cf3ae457"},"outputs":[],"source":["pip install tensorflow_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"executionInfo":{"elapsed":11,"status":"error","timestamp":1717399238722,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"TEUH3kAD9ZLx","outputId":"6a16c0e8-38af-4141-e6f4-4a816351bf3b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from annoy import AnnoyIndex\n","from sklearn.cluster import KMeans\n","\n","# Load data\n","def load_data(file_path):\n","    data = pd.read_csv(file_path)\n","    data = data[['Label', 'Title', 'Harga', 'Asal Kota']]  # Selecting the relevant columns\n","    return data\n","\n","# Preprocess the data\n","def preprocess(data):\n","    data['Title'] = data['Title'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n","    data['Asal Kota'] = data['Asal Kota'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n","    return data\n","\n","# Load the pre-trained model from TensorFlow Hub\n","embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","\n","# Generate embeddings\n","def get_embeddings(data):\n","    embeddings = embed(data['Title'])\n","    return embeddings.numpy()\n","\n","# Build Annoy index for efficient similarity search\n","def build_index(embeddings):\n","    dimension = embeddings.shape[1]  # Dimensions of embeddings\n","    index = AnnoyIndex(dimension, 'angular')\n","    for i, vector in enumerate(embeddings):\n","        index.add_item(i, vector)\n","    index.build(10)  # More trees, more precision\n","    return index\n","\n","# Cluster data for recommendations\n","def cluster_data(embeddings, num_clusters=10):\n","    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(embeddings)\n","    return kmeans.labels_\n","\n","# Search and recommend products\n","def search_and_recommend(query, index, data, embeddings, kmeans_labels, num_results=10):\n","    query_embedding = embed([query]).numpy()[0]\n","    indices = index.get_nns_by_vector(query_embedding, num_results)\n","    primary_results = data.iloc[indices]\n","\n","    # Recommend additional items from the same cluster\n","    if not primary_results.empty:\n","        cluster_label = primary_results['Cluster'].mode()[0]\n","        additional_suggestions = data[data['Cluster'] == cluster_label].sample(n=5)\n","        return pd.concat([primary_results, additional_suggestions]).drop_duplicates()\n","    return primary_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9iGggng_SIf"},"outputs":[],"source":["# Main function to execute the process\n","def main(file_path):\n","    data = load_data(file_path)\n","    data = preprocess(data)\n","    embeddings = get_embeddings(data)\n","    index = build_index(embeddings)\n","    data['Cluster'] = cluster_data(embeddings)\n","\n","    # Example search\n","    query = \"kasur kos\"\n","    results = search_and_recommend(query, index, data, embeddings, data['Cluster'])\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"elapsed":5534,"status":"ok","timestamp":1717081439370,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"qUjf5t49-1rj","outputId":"84869796-6244-4ae7-f47b-6949c368510f"},"outputs":[],"source":["# Hasil Rekomendasi\n","main('/content/shopee.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83341,"status":"ok","timestamp":1717397412825,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"3vplR73EjiJU","outputId":"dba456fd-54a4-420c-86b5-9c763ef18ae5"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","# Sample data (product titles and corresponding recommendations)\n","product_titles = data['Title']\n","\n","recommendations = list(data['Label'])\n","\n","# Tokenize product titles\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(product_titles)\n","sequences = tokenizer.texts_to_sequences(product_titles)\n","\n","# Padding sequences\n","max_sequence_length = max([len(seq) for seq in sequences])\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n","\n","# Convert recommendations to one-hot encoding\n","recommendation_classes = sorted(list(set(recommendations)))\n","recommendations_one_hot = np.zeros((len(recommendations), len(recommendation_classes)))\n","for i, rec in enumerate(recommendations):\n","    idx = recommendation_classes.index(rec)\n","    recommendations_one_hot[i, idx] = 1\n","\n","# Build a simple Sequential model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=16, input_length=max_sequence_length),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.Dense(16, activation='relu'),\n","    tf.keras.layers.Dense(len(recommendation_classes), activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(padded_sequences, recommendations_one_hot, epochs=10, batch_size=1)\n","\n","# Predict recommendations for new product titles\n","new_product_titles = [\"Meja Belajar Anak\"]\n","new_sequences = tokenizer.texts_to_sequences(new_product_titles)\n","new_padded_sequences = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')\n","predictions = model.predict(new_padded_sequences)\n","\n","# Get the top 20 predictions\n","top_indices = np.argsort(predictions, axis=1)[:, -20:][0]\n","top_predictions = predictions[0][top_indices]\n","\n","# Output the top 20 predictions\n","output_predictions = []\n","for i, idx in enumerate(top_indices):\n","    output_predictions.append((recommendation_classes[idx], top_predictions[i]))\n","\n","print(output_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1717397426059,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"mE-FTw9esjAX","outputId":"5e26e970-3d0e-4159-9bb2-88daf6e2836f"},"outputs":[],"source":["predicted_class_index = np.argmax(predictions)\n","\n","# Use the predicted class index to recommend a product\n","recommended_product = recommendations[predicted_class_index]\n","\n","print(\"Recommended Product:\", recommended_product)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":605,"status":"error","timestamp":1717397741030,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"EUJXRYme2BvR","outputId":"7804bc1c-8b66-4a2f-a41b-9b30fef79ff5"},"outputs":[],"source":["# Step 1: Load the CSV File\n","df = data\n","df.head()\n","\n","# Step 2: Preprocess Data\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n","tokenizer.fit_on_texts(df['Title'].values)\n","word_index = tokenizer.word_index\n","\n","sequences = tokenizer.texts_to_sequences(df['Title'].values)\n","padded_sequences = pad_sequences(sequences, padding='post')\n","\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['Title'].values, test_size=0.2, random_state=42)\n","\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","print(\"Shape of X_train:\", X_train.shape)\n","print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n","print(\"Shape of X_test:\", X_test.shape)\n","print(\"Shape of y_test_encoded:\", y_test_encoded.shape)\n","\n","# Step 3: Build and Train the Model\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, GlobalAveragePooling1D\n","\n","embedding_dim = 50\n","max_length = len(padded_sequences[0])\n","\n","inputs = Input(shape=(max_length,))\n","x = Embedding(input_dim=5000, output_dim=embedding_dim, input_length=max_length)(inputs)\n","x = LSTM(64, return_sequences=True)(x)\n","x = GlobalAveragePooling1D()(x)\n","x = Dropout(0.5)(x)\n","outputs = Dense(len(label_encoder.classes_), activation='softmax')(x)\n","\n","model = Model(inputs, outputs)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","history = model.fit(\n","    X_train, y_train_encoded,\n","    epochs=10,\n","    validation_data=(X_test, y_test_encoded),\n","    batch_size=16,\n","    verbose=1\n",")\n","\n","# Step 4: Make Recommendations\n","def recommend_products(title, model, tokenizer, label_encoder, num_recommendations=3):\n","    sequence = tokenizer.texts_to_sequences([title])\n","    padded_sequence = pad_sequences(sequence, maxlen=len(padded_sequences[0]), padding='post')\n","    predictions = model.predict(padded_sequence).flatten()\n","    top_indices = predictions.argsort()[-num_recommendations:][::-1]\n","\n","    recommended_titles = [label_encoder.inverse_transform([i])[0] for i in top_indices]\n","\n","    return recommended_titles\n","\n","# Example: Recommend products for a given title\n","title = \"Meja kerja kayu untuk kantor\"\n","recommendations = recommend_products(title, model, tokenizer, label_encoder)\n","print(\"Recommended product titles for the title '{}': {}\".format(title, recommendations))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9510,"status":"ok","timestamp":1717399089184,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"PZ2AmdIZ5rjd","outputId":"aa57b60f-6217-49aa-95cb-3fcf96bf6073"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, concatenate\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","\n","# Encode the product titles and labels\n","title_encoder = LabelEncoder()\n","data['Title_encoded'] = title_encoder.fit_transform(data['Title'])\n","\n","label_encoder = LabelEncoder()\n","data['Label_encoded'] = label_encoder.fit_transform(data['Label'])\n","\n","# Normalize the product IDs\n","scaler = MinMaxScaler()\n","data['Product ID'] = scaler.fit_transform(data['Product ID'].values.reshape(-1, 1))\n","\n","# Prepare arrays\n","product_ids = data['Product ID'].values\n","titles = data['Title_encoded'].values\n","labels = data['Label_encoded'].values\n","\n","# Split data into train and test sets\n","train_product_ids, test_product_ids, train_titles, test_titles, train_labels, test_labels = train_test_split(product_ids, titles, labels, test_size=0.2, random_state=42)\n","\n","# Define inputs\n","input_product = Input(shape=(1,), name='Product')\n","input_title = Input(shape=(1,), name='Title')\n","input_label = Input(shape=(1,), name='Label')\n","\n","# Define embedding layers\n","embedding_product = Embedding(input_dim=len(data['Product ID']) + 1, output_dim=50)(input_product)\n","embedding_title = Embedding(input_dim=len(data['Title_encoded']) + 1, output_dim=50)(input_title)\n","embedding_label = Embedding(input_dim=len(data['Label_encoded']) + 1, output_dim=50)(input_label)\n","\n","# Flatten embedding layers\n","flat_product = Flatten()(embedding_product)\n","flat_title = Flatten()(embedding_title)\n","flat_label = Flatten()(embedding_label)\n","\n","# Concatenate embeddings\n","concat = concatenate([flat_product, flat_title, flat_label])\n","\n","# Add dense layers\n","dense_1 = Dense(256, activation='relu')(concat)\n","dropout_1 = Dropout(0.5)(dense_1)\n","dense_2 = Dense(128, activation='relu')(dropout_1)\n","dropout_2 = Dropout(0.5)(dense_2)\n","output = Dense(1, activation='linear')(dropout_2)\n","\n","# Define the model\n","model = Model(inputs=[input_product, input_title, input_label], outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","# Reshape the data to fit the model input\n","train_product_ids = train_product_ids.reshape(-1, 1)\n","test_product_ids = test_product_ids.reshape(-1, 1)\n","train_titles = train_titles.reshape(-1, 1)\n","test_titles = test_titles.reshape(-1, 1)\n","train_labels = train_labels.reshape(-1, 1)\n","test_labels = test_labels.reshape(-1, 1)\n","\n","# Define early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Train the model\n","model.fit([train_product_ids, train_titles, train_labels], train_titles, epochs=100, batch_size=64, verbose=1, validation_data=([test_product_ids, test_titles, test_labels], test_titles), callbacks=[early_stopping])\n","\n","# Function to get product recommendations based on model predictions\n","def get_recommendations(product_id, title, label, model, top_n=10):\n","    # Create an array of product IDs to predict\n","    all_product_ids = np.array(product_ids).reshape(-1, 1)\n","    all_titles = np.array(titles).reshape(-1, 1)\n","    all_labels = np.array(labels).reshape(-1, 1)\n","\n","    # Predict the titles for all products\n","    predicted_titles = model.predict([all_product_ids, all_titles, all_labels]).flatten()\n","\n","    # Get the indices of the top N predictions\n","    top_indices = np.argsort(predicted_titles)[-top_n:]\n","\n","    # Return the top N product IDs\n","    return product_ids[top_indices]\n","\n","# Function to search for products and get recommendations\n","def search_and_recommend(search_term, data, model, top_n=10):\n","    # Filter the products based on the search term\n","    filtered_data = data[data['Title'].str.contains(search_term, case=False, na=False)]\n","\n","    if filtered_data.empty:\n","        return pd.DataFrame(columns=['Recommended Product Titles'])\n","\n","    # Use the first product ID from the filtered results for recommendations\n","    sample_product_id = filtered_data['Product ID'].values[0]\n","    sample_title = filtered_data['Title_encoded'].values[0]\n","    sample_label = filtered_data['Label_encoded'].values[0]\n","    recommended_product_ids = get_recommendations(sample_product_id, sample_title, sample_label, model, top_n=top_n)\n","\n","    # Get the recommended product titles\n","    recommended_products_titles = data[data['Product ID'].isin(recommended_product_ids)]['Title']\n","\n","    # Ensure the recommended products are similar to the search term\n","    recommended_products_titles = recommended_products_titles[recommended_products_titles.str.contains(search_term, case=False, na=False)]\n","\n","    # Create a DataFrame to display the recommended product titles as a column\n","    recommendations_df = pd.DataFrame(recommended_products_titles.tolist(), columns=['Recommended Product Titles'])\n","\n","    return recommendations_df\n","\n","# Example usage: search for \"Meja Belajar\" and get recommendations\n","search_term = \"Meja Belajar\"\n","recommendations_df = search_and_recommend(search_term, data, model)\n","\n","# Display the recommendations\n","print(recommendations_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1717399177687,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"-MUQUHsz90zs","outputId":"b38e6087-4606-4c07-b5af-3a8c551e07b6"},"outputs":[],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","# Define a function to clean the data\n","def clean_data(df):\n","    df = df.dropna(subset=['Title'])  # Drop rows with missing titles\n","    df = df.reset_index(drop=True)    # Reset index after dropping rows\n","    return df\n","\n","# Clean the data\n","data = clean_data(data)\n","\n","# Vectorize the product titles using TF-IDF\n","tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n","tfidf_matrix = tfidf_vectorizer.fit_transform(data['Title'])\n","\n","# Compute the cosine similarity matrix\n","cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n","\n","# Function to get product recommendations based on title similarity\n","def get_recommendations(title, cosine_sim=cosine_sim):\n","    # Find the index of the product that matches the title\n","    idx = data[data['Title'].str.contains(title, case=False, na=False)].index[0]\n","\n","    # Get the pairwise similarity scores of all products with the specified product\n","    sim_scores = list(enumerate(cosine_sim[idx]))\n","\n","    # Sort the products based on the similarity scores\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","\n","    # Get the indices of the top 10 most similar products\n","    sim_scores = sim_scores[1:11]\n","\n","    # Get the product indices\n","    product_indices = [i[0] for i in sim_scores]\n","\n","    # Return the top 10 most similar product titles\n","    return data['Title'].iloc[product_indices]\n","\n","# Example usage: search for \"Meja Belajar\" and get recommendations\n","search_term = \"Meja kayu\"\n","recommendations = get_recommendations(search_term)\n","\n","# Display the recommendations\n","print(\"Recommended Product Titles:\")\n","for i, title in enumerate(recommendations):\n","    print(f\"{i + 1}. {title}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":953,"status":"ok","timestamp":1717399992624,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"aLJkVMpfAnKc","outputId":"e55522a6-4338-4696-86ac-87cb0f280356"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, Flatten, Dense, Input\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Prepare data\n","titles = data['Title'].tolist()\n","labels = data['Label'].tolist()\n","\n","# Combine title and label for better semantic understanding\n","combined_text = [f\"{label} {title}\" for label, title in zip(labels, titles)]\n","\n","# Tokenize the combined text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(combined_text)\n","sequences = tokenizer.texts_to_sequences(combined_text)\n","word_index = tokenizer.word_index\n","vocab_size = len(word_index) + 1\n","\n","# Pad sequences\n","max_sequence_length = max(len(seq) for seq in sequences)\n","data_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n","\n","# Define the model\n","embedding_dim = 50\n","\n","model = Sequential()\n","model.add(Input(shape=(max_sequence_length,)))\n","model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(embedding_dim, activation='linear'))\n","\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","model.fit\n","model.summary()\n","\n","# Generate embeddings for the product descriptions\n","embeddings = model.predict(data_padded)\n","\n","# Define the search function\n","def semantic_search(query, embeddings, data, tokenizer, model, max_sequence_length, top_k=10):\n","    # Tokenize and pad the query\n","    query_seq = tokenizer.texts_to_sequences([query])\n","    query_padded = pad_sequences(query_seq, maxlen=max_sequence_length, padding='post')\n","\n","    # Generate the embedding for the query\n","    query_embedding = model.predict(query_padded)\n","\n","    # Calculate cosine similarities\n","    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n","\n","    # Get the top_k products\n","    top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n","    results = data.iloc[top_k_indices]\n","    return results\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378,"status":"ok","timestamp":1717399943430,"user":{"displayName":"Akbar Maulana Ibrahim M004D4KY3332","userId":"11704943035037494098"},"user_tz":-420},"id":"U3kh4PWsAxKW","outputId":"baed3edd-f6d4-4b96-ca77-ce3ddc8853bc"},"outputs":[],"source":["# Example usage\n","query = \"meja\"\n","results = semantic_search(query, embeddings, data, tokenizer, model, max_sequence_length, top_k=20)\n","\n","print(results)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
