{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow python-dotenv pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully fetched from http://161.97.109.65:3000/api/users\n",
      "                        _id       firstname       lastname         username  \\\n",
      "0  6665e9847aa0dfec0ad43b26         Machine       Learning  machinelearning   \n",
      "1  6665eab57aa0dfec0ad43b2a  DummyFirstname  DummyLastname       dummydata1   \n",
      "2  6665eac87aa0dfec0ad43b2d  DummyFirstname  DummyLastname       dummydata2   \n",
      "3  6665eacc7aa0dfec0ad43b30  DummyFirstname  DummyLastname       dummydata3   \n",
      "4  6665eacf7aa0dfec0ad43b33  DummyFirstname  DummyLastname       dummydata4   \n",
      "\n",
      "                  email         phone  \\\n",
      "0          ml@admin.com    7777777777   \n",
      "1  dummydata1@admin.com  777777770001   \n",
      "2  dummydata2@admin.com  777777770002   \n",
      "3  dummydata3@admin.com  777777770003   \n",
      "4  dummydata4@admin.com  777777770004   \n",
      "\n",
      "                                            password           address  \\\n",
      "0  $2a$10$oNSoSQcmxvHAefk5dKx0UuJw8oSdGeCumA.ZqIN...  Bangkit Capstone   \n",
      "1  $2a$10$ihldsbescWBR9v94/sRhReBpX8mZMGrRpwkUohU...   Dummy Address 1   \n",
      "2  $2a$10$IipmxQztB7MnyyTVUka6n.IK9C/wdqcEf8SXZjD...   Dummy Address 2   \n",
      "3  $2a$10$mQEfWkNV4c6.E6glZRmlyuNzrAVKctoLLXMv2pK...   Dummy Address 3   \n",
      "4  $2a$10$GYFAH4GoxInzAr8WkAeUEuLTYD5ZLjFumTyR2ZP...   Dummy Address 4   \n",
      "\n",
      "                        avatar   role                 createdat  \\\n",
      "0  /uploads/default_avatar.png  buyer  2024-06-09T17:42:28.211Z   \n",
      "1  /uploads/default_avatar.png  buyer  2024-06-09T17:47:33.477Z   \n",
      "2  /uploads/default_avatar.png  buyer  2024-06-09T17:47:52.685Z   \n",
      "3  /uploads/default_avatar.png  buyer  2024-06-09T17:47:56.118Z   \n",
      "4  /uploads/default_avatar.png  buyer  2024-06-09T17:47:59.747Z   \n",
      "\n",
      "                  updatedat ratings  __v  \n",
      "0  2024-06-09T17:42:28.211Z      []    0  \n",
      "1  2024-06-09T17:47:33.477Z      []    0  \n",
      "2  2024-06-09T17:47:52.685Z      []    0  \n",
      "3  2024-06-09T17:47:56.118Z      []    0  \n",
      "4  2024-06-09T17:47:59.747Z      []    0  \n",
      "Data successfully fetched from http://161.97.109.65:3000/api/products\n",
      "                        _id category     price  \\\n",
      "0  6667ef73b3e75416b2fa7e33     Meja  155000.0   \n",
      "1  6667ef73b3e75416b2fa7e34     Meja  124000.0   \n",
      "2  6667ef73b3e75416b2fa7e35     Meja  107000.0   \n",
      "3  6667ef73b3e75416b2fa7e36     Meja   99500.0   \n",
      "4  6667ef73b3e75416b2fa7e37     Meja  446000.0   \n",
      "\n",
      "                                                name  \\\n",
      "0  Damaindah Meja Belajar Kayu Set Kursi / Meja B...   \n",
      "1  Homedoki Meja / Meja Makan / Meja Komputer / M...   \n",
      "2  Sakula Meja kantor meja kerja Meja Komputer Pe...   \n",
      "3  Meja Portable Stand Laptop Meja Laptop Standin...   \n",
      "4  PiPi Furniture Meja Gaming / Meja komputer / M...   \n",
      "\n",
      "                   sellerId  \\\n",
      "0  6665e9847aa0dfec0ad43b26   \n",
      "1  6665e9847aa0dfec0ad43b26   \n",
      "2  6665e9847aa0dfec0ad43b26   \n",
      "3  6665e9847aa0dfec0ad43b26   \n",
      "4  6665e9847aa0dfec0ad43b26   \n",
      "\n",
      "                                        productImage  __v  \n",
      "0  [https://storage.googleapis.com/kelas-app-test...    0  \n",
      "1  [https://storage.googleapis.com/kelas-app-test...    0  \n",
      "2  [https://storage.googleapis.com/kelas-app-test...    0  \n",
      "3  [https://storage.googleapis.com/kelas-app-test...    0  \n",
      "4  [https://storage.googleapis.com/kelas-app-test...    0  \n",
      "Data successfully fetched from http://161.97.109.65:3000/api/interactions\n",
      "                                        interactions\n",
      "0  {'_id': '6667f373b3e75416b2fa83a7', 'userId': ...\n",
      "1  {'_id': '6667f373b3e75416b2fa83a8', 'userId': ...\n",
      "2  {'_id': '6667f373b3e75416b2fa83a9', 'userId': ...\n",
      "3  {'_id': '6667f373b3e75416b2fa83aa', 'userId': ...\n",
      "4  {'_id': '6667f373b3e75416b2fa83ab', 'userId': ...\n",
      "All data fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Load environment variables from .env file\n",
    "jwt_token = os.getenv('JWT_TOKEN')\n",
    "\n",
    "headers = {'Authorization': f'Bearer {jwt_token}'}\n",
    "\n",
    "api_urls = {\n",
    "    'interactions': 'http://161.97.109.65:3000/api/interactions',\n",
    "    'users': 'http://161.97.109.65:3000/api/users',\n",
    "    'products': 'http://161.97.109.65:3000/api/products'\n",
    "}\n",
    "\n",
    "def fetch_data(url, headers):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad requests\n",
    "        data = pd.DataFrame(response.json())\n",
    "        print(f\"Data successfully fetched from {url}\")\n",
    "        print(data.head())  # Display the first few rows of the DataFrame\n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Failed to fetch data from {url}: {str(e)}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch data from APIs\n",
    "users = fetch_data(api_urls['users'], headers)\n",
    "products = fetch_data(api_urls['products'], headers)\n",
    "interactions = fetch_data(api_urls['interactions'], headers)\n",
    "\n",
    "# Check if data was fetched successfully\n",
    "if not users.empty and not products.empty and not interactions.empty:\n",
    "    print(\"All data fetched successfully.\")\n",
    "else:\n",
    "    print(\"Data fetching failed, check errors and retry.\")\n",
    "    # Optionally, add logic to halt further processing if data is crucial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume 'interactions' is a DataFrame with a column containing dictionaries\n",
    "# First, ensure that the 'interactions' column is appropriately normalized\n",
    "if 'interactions' in interactions.columns:\n",
    "    interactions_expanded = pd.json_normalize(interactions['interactions'])\n",
    "else:\n",
    "    interactions_expanded = pd.json_normalize(interactions.iloc[:, 0])  # If 'interactions' is the name of DataFrame and not a column\n",
    "\n",
    "# Assuming the JSON data has keys 'userId', 'productId', and 'interactionValue'\n",
    "interactions_expanded['user_id'] = interactions_expanded['userId']\n",
    "interactions_expanded['product_id'] = interactions_expanded['productId']\n",
    "interactions_expanded['interaction_value'] = interactions_expanded['interactionValue']\n",
    "\n",
    "# Encode user_id and product_id\n",
    "user_ids = interactions_expanded['user_id'].unique().tolist()\n",
    "product_ids = interactions_expanded['product_id'].unique().tolist()\n",
    "\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "product2product_encoded = {x: i for i, x in enumerate(product_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "productencoded2product = {i: x for i, x in enumerate(product_ids)}\n",
    "\n",
    "interactions_expanded['user'] = interactions_expanded['user_id'].map(user2user_encoded)\n",
    "interactions_expanded['product'] = interactions_expanded['product_id'].map(product2product_encoded)\n",
    "\n",
    "# Split the data\n",
    "train, test = train_test_split(interactions_expanded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data into required format\n",
    "x_train = [train['user'].values, train['product'].values]\n",
    "y_train = train['interaction_value'].values\n",
    "x_test = [test['user'].values, test['product'].values]\n",
    "y_test = test['interaction_value'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=(1,))\n",
    "user_embedding = Embedding(len(user2user_encoded), 50)(user_input)  # Removed input_length\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "product_input = Input(shape=(1,))\n",
    "product_embedding = Embedding(len(product2product_encoded), 50)(product_input)  # Removed input_length\n",
    "product_vec = Flatten()(product_embedding)\n",
    "\n",
    "dot_product = Dot(axes=1)([user_vec, product_vec])\n",
    "model = Model(inputs=[user_input, product_input], outputs=dot_product)\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - val_loss: 3.8771\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 3.8748\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0130 - val_loss: 3.8771\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0216 - val_loss: 3.8738\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 3.8738\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 3.8726\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 3.8738\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 3.8724\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0205 - val_loss: 3.8728\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 3.8715\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0198 - val_loss: 3.8720\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 3.8718\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0181 - val_loss: 3.8695\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0193 - val_loss: 3.8685\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0157 - val_loss: 3.8698\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 3.8672\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - val_loss: 3.8697\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 3.8672\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 3.8702\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0127 - val_loss: 3.8665\n",
      "Epoch 1/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0098\n",
      "Epoch 1: val_loss improved from inf to 3.86694, saving model to ..\\model\\best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 - val_loss: 3.8669\n",
      "Epoch 2/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0475\n",
      "Epoch 2: val_loss improved from 3.86694 to 3.86556, saving model to ..\\model\\best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - val_loss: 3.8656\n",
      "Epoch 3/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0102\n",
      "Epoch 3: val_loss did not improve from 3.86556\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191 - val_loss: 3.8657\n",
      "Epoch 4/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031\n",
      "Epoch 4: val_loss improved from 3.86556 to 3.86428, saving model to ..\\model\\best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 3.8643\n",
      "Epoch 5/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023\n",
      "Epoch 5: val_loss did not improve from 3.86428\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 3.8664\n",
      "Epoch 6/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017\n",
      "Epoch 6: val_loss improved from 3.86428 to 3.86066, saving model to ..\\model\\best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 3.8607\n",
      "Epoch 7/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0091\n",
      "Epoch 7: val_loss did not improve from 3.86066\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - val_loss: 3.8664\n",
      "Epoch 8/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026\n",
      "Epoch 8: val_loss improved from 3.86066 to 3.85892, saving model to ..\\model\\best_model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 3.8589\n",
      "Epoch 9/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020\n",
      "Epoch 9: val_loss did not improve from 3.85892\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0160 - val_loss: 3.8654\n",
      "Epoch 10/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017\n",
      "Epoch 10: val_loss did not improve from 3.85892\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - val_loss: 3.8615\n",
      "Epoch 11/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025\n",
      "Epoch 11: val_loss did not improve from 3.85892\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 3.8633\n",
      "Epoch 12/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0129\n",
      "Epoch 12: val_loss did not improve from 3.85892\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 3.8600\n",
      "Epoch 13/20\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0015\n",
      "Epoch 13: val_loss did not improve from 3.85892\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 3.8619\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'train' and 'test' datasets are already split and preprocessed\n",
    "x_train = [np.array(train['user']), np.array(train['product'])]\n",
    "y_train = np.array(train['interaction_value'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    verbose=1, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Optionally, you can add callbacks, for example to save the best model or early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the path to the model directory\n",
    "model_dir = os.path.join('..', 'model', 'best_model.keras')\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(model_dir, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    verbose=1, \n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 666545a42b9108ea2b463d87 not found.\n",
      "Recommended products for user 666545a42b9108ea2b463d87:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Function to get recommendations for a specific user\n",
    "def recommend_products(user_id, model, interactions, user2user_encoded, product2product_encoded, productencoded2product, products, top_n=30):\n",
    "    # Check if user_id is in the encoding map\n",
    "    if user_id not in user2user_encoded:\n",
    "        print(f\"User ID {user_id} not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    user_encoded = user2user_encoded[user_id]\n",
    "    # Get all encoded product IDs as a list of integers\n",
    "    product_ids = list(product2product_encoded.values())\n",
    "\n",
    "    # Create user-product array for prediction\n",
    "    # Ensure all entries are integers for the model input\n",
    "    user_product_array = np.array([[user_encoded] * len(product_ids), product_ids]).T.astype(int)\n",
    "\n",
    "    # Predict interaction values using the model\n",
    "    predictions = model.predict([user_product_array[:, 0], user_product_array[:, 1]])\n",
    "    predictions = predictions.flatten()\n",
    "\n",
    "    # Get top N product indices\n",
    "    top_indices = predictions.argsort()[-top_n:][::-1]\n",
    "    # Decode the top indices to product IDs\n",
    "    recommended_product_ids = [productencoded2product[x] for x in top_indices]\n",
    "\n",
    "    # Filter the products DataFrame to get recommended products using the correct column name\n",
    "    recommended_products = products[products['_id'].isin(recommended_product_ids)]\n",
    "    return recommended_products\n",
    "\n",
    "# Try the model with the specified user ID\n",
    "user_id = '666545a42b9108ea2b463d87'\n",
    "recommended_products = recommend_products(user_id, model, interactions, user2user_encoded, product2product_encoded, productencoded2product, products)\n",
    "print(f\"Recommended products for user {user_id}:\")\n",
    "print(recommended_products)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
